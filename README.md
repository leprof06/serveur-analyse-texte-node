ğŸ“ Serveur dâ€™analyse de texte (Node.js)

API REST lÃ©gÃ¨re pour analyser des productions Ã©crites multilinguesÂ : dÃ©tection de langue, correction LanguageTool, similaritÃ© lexicale et sÃ©mantique (HuggingÂ Face), heuristiques de structure, et agrÃ©gation dâ€™un score CECRL (content/organization/lexis/grammar/mechanics).

StatutÂ : prÃªt pour un dÃ©pÃ´t public. Aucune donnÃ©e sensible dans le code. Les clÃ©s/API passent par les variables dâ€™environnement.

âœ¨ FonctionnalitÃ©s

DÃ©tection de langue (ISOâ€‘639â€‘1) via franc-min â†’ utils/lang.js mappe iso3 â†’ iso2.

Correction grammaticale & orthographique via LanguageToolÂ :

API publique ou instance self-host (configurable via LT_BASE_URL + LT_API_KEY).

SimilaritÃ© lexicale (forme) avec string-similarity (0â€“100).

SimilaritÃ© sÃ©mantique (sens) avec HuggingÂ Face Inference API (embeddings + cosinus, 0â€“100).

Heuristiques de structureÂ : prÃ©sence de verbes (EN + heuristiques FR), score de motsâ€‘clÃ©s.

Ã‰valuation de contenu configurable par questionÂ : motsâ€‘clÃ©s all/any/banned, regex, longueur min/max, verbe requis, similaritÃ©.

AgrÃ©gateur CECRL (pondÃ©rations dans rubrics/cefr_rubric.json) â†’ overall + breakdown.

API ExpressÂ : CORS whitelist, logging (morgan), rate limit (60 req/min/IP), healthcheck.

ğŸ§© Architecture (fichiers clÃ©s)

.
â”œâ”€ index.js                 # EntrÃ©e serveur (routes, CORS, rate-limit, health)
â”œâ”€ evaluation.js            # Ã‰valuation de contenu (similaritÃ©/keywords/regex/longueur/verbe)
â”œâ”€ scoring.js               # SimilaritÃ© lexicale + scores grammaire/orthographe + heuristiques
â”œâ”€ semantic.js              # SimilaritÃ© sÃ©mantique (HF Inference API)
â”œâ”€ languagetool.js          # Client LanguageTool (public ou self-host)
â”œâ”€ rubricScoring.js         # AgrÃ©gation CECRL (content/organization/lexis/grammar/mechanics)
â”œâ”€ lexis.js                 # Indicateurs lexicaux (TTR, rÃ©pÃ©titions)
â”œâ”€ organization.js          # Indicateurs de structure (paragraphes, connecteurs)
â”œâ”€ utils/
â”‚   â””â”€ lang.js              # Mapping iso3 â†’ iso2 (franc-min)
â””â”€ rubrics/
    â””â”€ cefr_rubric.json     # PondÃ©rations CECRL par dÃ©faut

ğŸ”§ PrÃ©requis

Node.jsÂ â‰¥Â 18

AccÃ¨s Internet sortant (LanguageTool public ou votre instance selfâ€‘host + HuggingÂ Face)

ğŸ“¦ Installation

# 1) Cloner
git clone https://github.com/<user>/serveur-analyse-texte-node.git
cd serveur-analyse-texte-node

# 2) DÃ©pendances
npm install

# 3) Variables dâ€™environnement
cp .env.example .env   # crÃ©ez .env si absent et complÃ©tez les valeurs

# 4) Lancer en dev
npm start               # Ã©coute sur PORT (par dÃ©faut 8080)
# ou
node index.js

.env.example

# Port dâ€™Ã©coute HTTP
PORT=8080

# LanguageTool
# - Lâ€™un OU lâ€™autreÂ : soit API publique (laisser LT_BASE_URL vide, Ã©ventuellement LT_API_KEY),
#   soit votre instance self-host (dÃ©finir LT_BASE_URL, et LT_API_KEY si configurÃ©e cÃ´tÃ© serveur)
LT_BASE_URL=
LT_API_KEY=

# SimilaritÃ© sÃ©mantique Hugging Face (obligatoire pour semanticScore)
HF_API_KEY=
# ModÃ¨le dâ€™embeddings (multilingue conseillÃ©)
HF_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# PondÃ©ration pÃ©nalitÃ© par erreur LanguageTool (optionnel)
GRAMMAR_PTS_PER_ERROR=6
SPELLING_PTS_PER_ERROR=5

# CORS (liste dâ€™origines autorisÃ©es, sÃ©parÃ©es par des virgules). "*" = tout (dÃ©faut).
CORS_ORIGINS=*

ğŸ”’ SÃ©curitÃ©Â : ne commitez jamais .env. Fournissez seulement un .env.example sans secrets.

ğŸš¦ DÃ©marrage & santÃ©

DÃ©marrerÂ : npm start â†’ http://0.0.0.0:<PORT>

HealthcheckÂ : GET /health â†’ { status: "ok", uptime, ts }

Rate limitÂ : 60 req/min/IP (configurÃ©e dans index.js).

ğŸ”Œ Endpoints

POST /analyse-text

Corps JSONÂ :

{
  "text": "rÃ©ponse de l'Ã©lÃ¨ve",
  "expectedAnswer": "rÃ©ponse attendue (facultatif)",
  "expectedLang": "fr" ,
  "keywords": ["mot1", "mot2"],
  "eval": {
    "expectedAnswer": "...",                 
    "similarityThreshold": 70,                 
    "keywords": { "all": ["..."], "any": ["..."], "banned": ["..."] },
    "anyAtLeast": 1,                          
    "regex": ["\\bexpr(?:ession)?\\b"],  
    "minWords": 30, "maxWords": 120,         
    "requireVerb": true,                      
    "weights": {                              
      "similarity": 60, "all": 25, "any": 15,
      "regex": 20, "length": 10, "verb": 10, "penaltyBanned": 30
    }
  }
}

text (requis)Â : texte Ã  analyser.

expectedAnswer (opt.)Â : texte de rÃ©fÃ©rence pour la similaritÃ© (lexicale + sÃ©mantique).

expectedLang (opt.)Â : langue attendue (ex. fr). Si diffÃ©rent de la dÃ©tection, un issue de type language est ajoutÃ©.

keywords (opt.)Â : liste de motsâ€‘clÃ©s utilisÃ©s par certaines heuristiques.

eval (opt.)Â : configuration dâ€™Ã©valuation de contenu (voir ciâ€‘dessus). Vous pouvez nâ€™en utiliser quâ€™une partie.

RÃ©ponseÂ :

{
  "lang": "fr",
  "grammarScore": 86,
  "spellingScore": 92,
  "similarityScore": 74,   
  "semanticScore": 81,     
  "issues": [
    {"type": "grammar", "message": "...", "ruleId": "...", "offset": 12, "length": 5, "replacements": ["..."]}
  ],
  "content": {
    "contentScore": 78,
    "isCorrect": true,
    "reasons": [
      {"rule": "similarity", "value": 81, "weight": 60, "points": 49, "threshold": 70},
      {"rule": "keywords_all", "found": 2, "total": 2, "pct": 100, "weight": 25, "points": 25},
      {"rule": "length", "wordCount": 65, "minWords": 30, "maxWords": 120, "weight": 10, "points": 10}
    ]
  },
  "rubric": {
    "overall": 80,
    "breakdown": {
      "content": 81,
      "organization": 74,
      "lexis": 77,
      "grammar": 86,
      "mechanics": 92
    },
    "details": {
      "semantic": 81,
      "organization": {"paragraphs": 2, "words": 120, "paraScore": 66, "connScore": 50},
      "lexis": {"total": 120, "types": 85, "ttr": 0.708, "ttrScore": 100, "repeatedTop": ["..."], "lexisScore": 90}
    }
  },
  "details": {
    "grammarErrors": 3,
    "spellingErrors": 1,
    "ltError": null,
    "hasVerb": true,
    "keywordScore": 100,
    "keywordsFound": 2,
    "keywordsTotal": 2
  }
}

semanticScore retourne null si HF_API_KEY nâ€™est pas renseignÃ©e.

Exemples curl

# Minimal (sans sÃ©mantique)
curl -sS http://localhost:8080/analyse-text \
  -H 'Content-Type: application/json' \
  -d '{"text":"Bonjour je m\'appelle Jean et je vis en France."}' | jq .

# Avec expectedAnswer + Ã©valuation de contenu
curl -sS http://localhost:8080/analyse-text \
  -H 'Content-Type: application/json' \
  -d '{
        "text":"Je m\'appelle Jean, j\'habite Ã  Paris et je travaille comme dÃ©veloppeur.",
        "expectedAnswer":"Je m\'appelle Paul, j\'habite en France et je suis ingÃ©nieur.",
        "expectedLang":"fr",
        "eval":{
          "expectedAnswer":"Je m\'appelle Paul, j\'habite en France et je suis ingÃ©nieur.",
          "similarityThreshold":70,
          "keywords":{"all":["habite","travaille"],"any":["France","Paris"],"banned":["!!!"]},
          "minWords":10,
          "requireVerb":true
        }
      }' | jq .

ğŸ§® DÃ©tails des calculs (rapide)

SimilaritÃ© lexicaleÂ : string-similarity sur textes normalisÃ©s (minuscules, diacritiques retirÃ©s, espaces compressÃ©s) â†’ 0â€“100.

SimilaritÃ© sÃ©mantiqueÂ : embeddings HuggingÂ Face (pipeline feature-extraction) â†’ moyenne spatiale â†’ cosinus â†’ 0â€“100.

Grammar/SpellingÂ : pÃ©nalitÃ© linÃ©aire par erreur LT (GRAMMAR_PTS_PER_ERROR, SPELLING_PTS_PER_ERROR), bornÃ© 0â€“100.

OrganizationÂ : nb. de paragraphes (â‰¥3 â‡’ 100) + connecteurs repÃ©rÃ©s (FR/EN) â†’ moyenne 50/50.

LexisÂ : TTR (typeâ€‘token ratio) + pÃ©nalitÃ© rÃ©pÃ©titions (â‰¥4 occurrences) â†’ 0â€“100.

Rubric CECRLÂ : pondÃ©rations dans rubrics/cefr_rubric.json (par dÃ©fautÂ : contentÂ 35, organizationÂ 15, lexisÂ 20, grammarÂ 20, mechanicsÂ 10).

ğŸ” SÃ©curitÃ© & bonnes pratiques

Ne placez aucune clÃ© en dur dans le code. Utilisez .env.

Limitez les origines CORS avec CORS_ORIGINS en production.

En charge Ã©levÃ©eÂ : self-host LanguageTool et pointez LT_BASE_URL.

Lâ€™endpoint HuggingÂ Face est appelÃ© avec un timeout (15s). GÃ©rez la rÃ©silience cÃ´tÃ© client.

ğŸš€ DÃ©ploiement (pistes)

Render / Railway / Fly.ioÂ : exposez PORT et variables .env. PrÃ©voir un keepâ€‘alive si la plateforme met en veille.

Docker (exemple minimal)

FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
ENV NODE_ENV=production
EXPOSE 8080
CMD ["node", "index.js"]

ğŸ§ª Tests manuels rapides

GET /health â†’ doit renvoyer status: ok.

POST /analyse-text uniquement avec text â†’ renvoie langue dÃ©tectÃ©e + scores sans sÃ©mantique.

Ajoutez HF_API_KEY â†’ semanticScore â‰  null.

Fixez expectedLang â‰  langue dÃ©tectÃ©e â†’ un issue language apparaÃ®t.

ğŸ“„ Licence

Choisissez et ajoutez un fichier LICENSE (MIT recommandÃ© si usage libre).

â„¹ï¸ Merci de simplement mentionner dans vos projets que la partie serveur dâ€™analyse de texte a Ã©tÃ© crÃ©Ã©e par Yann de support and Learn with yann alias leprof06 (pseudo de github) . Câ€™est tout ce qui est demandÃ©.

ğŸ™Œ Remerciements

LanguageTool

Hugging Face Inference API

franc-min

string-similarity

